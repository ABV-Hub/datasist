<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.2" />
<title>datasist.project API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>datasist.project</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import argparse  
import json
import joblib
import pickle
from pathlib import Path
import logging


def start_project(project_name=None):
    &#39;&#39;&#39;
    Creates a standard data science project directory. This helps in
    easy team collaboration, rapid prototyping, easy reproducibility and fast iteration. 
    
    The directory structure is by no means a globally recognized standard, but was inspired by
    the folder structure created by the Azure team (https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview)
    and Edward Ma (https://makcedward.github.io/) of OOCL.
    
    ### PROJECT STRUCTURE:

            ├── data
            │   ├── processed
            │   └── raw
            ├── outputs
            │   ├── models
            ├── src
            │   ├── scripts
            │       ├── ingest
            │       ├── modeling
            │       ├── preparation
            │       ├── test
            ├   ├── notebooks



            DETAILS:

            data: Stores data used for the experiments, including raw and intermediate processed data.
                processed: stores all processed data files after cleaning, analysis, feature creation etc.
                raw: Stores all raw data obtained from databases, file storages, etc.

            outputs:Stores all output files from an experiment.
                models: Stores trained binary model files. This are models saved after training and evaluation for later use.

            src: Stores all source code including scripts and notebook experiments.
                scripts: Stores all code scripts usually in Python/R format. This is usually refactored from the notebooks.
                    modeling: Stores all scripts and code relating to model building, evaluation and saving.
                    preparation: Stores all scripts used for data preparation and cleaning.
                    ingest: Stores all scripts used for reading in data from different sources like databases, web or file storage.
                    test: Stores all test files for code in scripts.
                notebooks: Stores all jupyter notebooks used for experimentation.
    
    
    Parameters:
    -------------
    project_name: String, Filepath
            Name of filepath of the directory to initialize and create folders.
    
    Returns:
    -------------
    None
    
    &#39;&#39;&#39;
    if project_name is None:
        raise ValueError(&#34;project_name: Expecting a string or filepath, got &#39;None&#39;&#34;)

    
    base_path = os.path.join(os.getcwd(), project_name)
    data_path = os.path.join(base_path, &#39;data&#39;)
    output_path = os.path.join(base_path, &#39;outputs&#39;)
    model_path = os.path.join(output_path, &#39;models&#39;)
    src_path = os.path.join(base_path, &#39;src&#39;)
    scripts_path = os.path.join(base_path, &#39;src&#39;, &#39;scripts&#39;)

    
    os.makedirs(data_path, exist_ok=True)
    os.makedirs(os.path.join(data_path, &#39;raw&#39;), exist_ok=True)
    os.makedirs(os.path.join(data_path, &#39;processed&#39;), exist_ok=True)

    os.makedirs(os.path.join(output_path), exist_ok=True)
    os.makedirs(os.path.join(model_path), exist_ok=True)

    os.makedirs(os.path.join(src_path), exist_ok=True)
    os.makedirs(os.path.join(src_path, &#39;notebooks&#39;), exist_ok=True)

    os.makedirs(os.path.join(scripts_path), exist_ok=True)
    os.makedirs(os.path.join(scripts_path, &#39;ingest&#39;), exist_ok=True)
    os.makedirs(os.path.join(scripts_path, &#39;preparation&#39;), exist_ok=True)
    os.makedirs(os.path.join(scripts_path, &#39;modeling&#39;), exist_ok=True)
    os.makedirs(os.path.join(scripts_path, &#39;test&#39;), exist_ok=True)


    
    desc = &#39;&#39;&#39;
    PROJECT STRUCTURE:

            ├── data
            │   ├── processed
            │   └── raw
            ├── outputs
            │   ├── models
            ├── src
            │   ├── scripts
            │       ├── ingest
            │       ├── modeling
            │       ├── preparation
            │       ├── test
            ├   ├── notebooks


            data: Stores data used for the experiments, including raw and intermediate processed data.
                processed: stores all processed data files after cleaning, analysis, feature creation etc.
                raw: Stores all raw data obtained from databases, file storages, etc.

            outputs:Stores all output files from an experiment.
                models: Stores trained binary model files. This are models saved after training and evaluation for later use.

            src: Stores all source code including scripts and notebook experiments.
                scripts: Stores all code scripts usually in Python/R format. This is usually refactored from the notebooks.
                    modeling: Stores all scripts and code relating to model building, evaluation and saving.
                    preparation: Stores all scripts used for data preparation and cleaning.
                    ingest: Stores all scripts used for reading in data from different sources like databases, web or file storage.
                    test: Stores all test files for code in scripts.
                notebooks: Stores all jupyter notebooks used for experimentation.

    &#39;&#39;&#39; 
    #project configuration settings
    json_config = {&#34;description&#34;: &#34;This file holds all confguration settings for the current project&#34;,
                    &#34;basepath&#34;: base_path,
                    &#34;datapath&#34; : data_path,
                    &#34;outputpath&#34;: output_path,
                    &#34;modelpath&#34;: model_path}
    
    #create a readme.txt file to explain the folder structure
    with open(os.path.join(base_path, &#34;README.txt&#34;), &#39;w&#39;) as readme:
        readme.write(desc)
    
    with open(os.path.join(base_path, &#34;config.txt&#34;), &#39;w&#39;) as configfile:
        json.dump(json_config, configfile)
    
    print(&#34;Project Initialized successfully in {}&#34;.format(base_path))
    print(&#34;Check folder description in ReadMe.txt&#34;)




def save_model(model, name=&#39;model&#39;, method=&#39;joblib&#39;):
    &#39;&#39;&#39;
    Save a trained machine learning model in the models folder.
    Folders must be initialized using the datasist start_project function.
    Creates a folder models if datasist standard directory is not provided.

    Parameters:
    ------------
    model: binary file, Python object
        Trained model file to save in the models folder.

    name: string
        Name of the model to save it with.

    method: string
        Format to use in saving the model. It can be one of [joblib, pickle or keras].

    Returns:
    ---------
    None

    &#39;&#39;&#39;

    if model is None:
        raise ValueError(&#34;model: Expecting a binary model file, got &#39;None&#39;&#34;)
   
    #get file path from config file
    #we assume that the user is saving the model from the models folder
    config = None

    try:
        homepath = _get_home_path(os.getcwd())
        config_path = os.path.join(homepath, &#39;config.txt&#39;)
        
        with open(config_path) as configfile:
            config = json.load(configfile)
        
        model_path = os.path.join(config[&#39;modelpath&#39;], name)

        if method is &#34;joblib&#34;:
            filename = model_path + &#39;.jbl&#39;
            joblib.dump(model, model_path)
            print(&#34;model saved in {}&#34;.format(filename))
        elif method is &#39;pickle&#39;:
            filename = model_path + &#39;.pkl&#39;
            pickle.dump(model, model_path)
            print(&#34;model saved in {}&#34;.format(filename))

        elif method is &#39;keras&#39;:
            filename = model_path + &#39;.h5&#39;
            model.save(filename)
            print(&#34;model saved in {}&#34;.format(filename))

        else:
            logging.error(&#34;{} not supported, specify one of [joblib, pickle, keras]&#34;.format(method))
            
    except FileNotFoundError as e:
        msg = &#34;models folder does not exist. Saving model to the {} folder. It is recommended that you start your project using datasist&#39;s start_project function&#34;.format(name)
        logging.info(msg)

        if method is &#34;joblib&#34;:
            filename = name + &#39;.jbl&#39;
            joblib.dump(model, filename)
            print(&#34;model saved in current working directory&#34;)
        elif method is &#39;pickle&#39;:
            filename = name + &#39;.pkl&#39;
            pickle.dump(model, filename)
            print(&#34;model saved in current working directory&#34;)

        elif method is &#39;keras&#39;:
            filename = name + &#39;.h5&#39;
            model.save(filename)
            print(&#34;model saved in current working directory&#34;)

        else:
            logging.error(&#34;{} not supported, specify one of [joblib, pickle, keras]&#34;.format(method))
            


def save_data(data, name=&#39;processed_data&#39;, method=&#39;joblib&#39;, loc=&#39;processed&#39;):
    
    &#39;&#39;&#39;
    Saves data in the data folder. The data folder contains the processed and raw subfolders.

    The processed subfolder holds data that have been processed by some methods and can be used for later computation. Files like
    feature matrixes, clean data files etc.

    The raw subfolder contains data in the raw format. This can be in the form of sql tables, csv files raw texts etc.
    Folders must be initialized using the datasist start_project function.

    Parameters:
    ------------
    data: binary strings, CSV, txt
        Data to save in the specified folder

    name: string, Default proc_data
        Name of the data file to save.

    method: string, Default None
        Format to use in saving the data. It can be empty string, and we assume it is a 
        Pandas DataFrame, and we use the to_csv function, else we serialize with joblib.
    
    loc: string, Default processed.
        subfolder to save the data file to. Can be one of [processed, raw ]

    Returns:
    ---------
    None

    &#39;&#39;&#39;
    if data is None:
        raise ValueError(&#34;data: Expecting a dataset, got &#39;None&#39;&#34;)

    if loc not in [&#39;processed&#39;, &#39;raw&#39;]:
        raise ValueError(&#34;loc: location not found, expecting one of [processed , raw] got {}&#34;.format(loc))
    
    try:
        homepath = _get_home_path(os.getcwd())
        config_path = os.path.join(homepath, &#39;config.txt&#39;)
        
        with open(config_path) as configfile:
            config = json.load(configfile)
        
        data_path = os.path.join(config[&#39;datapath&#39;], loc)


        if method is &#34;joblib&#34;:
            filename =  os.path.join(data_path, name) + &#39;.jbl&#39;
            joblib.dump(data, filename)
            print(&#34;Data saved in {}&#34;.format(filename))

        else:
            try:
                data.to_csv(os.path.join(data_path, name) + &#39;.csv&#39;, index=False)
                print(&#34;Data saved successfully&#34;)

            except AttributeError as e:
                print(&#34;The file to save must be a Pandas DataFrame. Otherwise, change method parameter to joblib &#34;)
                logging.error(e)                     


    except FileNotFoundError as e:
        msg = &#34;data folder does not exist. Saving data to the {} folder. It is recommended that you start your project using datasist&#39;s start_project function&#34;.format(name)
        logging.info(msg)

        if method is &#34;joblib&#34;:
            filename = name + &#39;.jbl&#39;
            joblib.dump(data, filename)
            print(&#34;data saved in current working directory&#34;)
        else:
            try:
                data.to_csv(name + &#39;.csv&#39;,  index=False)
            except AttributeError as e:
                logging.info(&#34;The file to save must be a Pandas DataFrame, else change method to joblib &#34;)
                logging.error(e)                 




def save_outputs(data=None, name=&#39;proc_outputs&#39;, method=&#39;joblib&#39;):

    &#39;&#39;&#39;
    Saves files like vocabulary, class labels, mappings, encodings, images etc. in the outputs folder. 
    
    Parameters:
    ------------
    data: binary strings, CSV, txt
        Data to save in the folder

    name: string, Default proc_outputs
        Name of the data file to save.

    method: string, Default joblib
        Format to use in saving the data. It can be one of [csv, joblib, pickle].

    Returns:
    ---------
    None

    &#39;&#39;&#39;
    if data is None:
        raise ValueError(&#34;data: Expecting a dataset, got &#39;None&#39;&#34;)

    if method not in [&#39;csv&#39;, &#39;joblib&#39;, &#39;pickle&#39;]:
        raise ValueError(&#34;method: Expecting one of [&#39;csv&#39;, &#39;joblib&#39;, &#39;pickle&#39;] got {}&#34;.format(method))
    
    try:
        homepath = _get_home_path(os.getcwd())
        config_path = os.path.join(homepath, &#39;config.txt&#39;)
        
        with open(config_path) as configfile:
            config = json.load(configfile)
        
        outputs_path = config[&#39;outputpath&#39;]


        if method is &#34;joblib&#34;:
            filename =  os.path.join(outputs_path, name) + &#39;.jbl&#39;
            joblib.dump(data, filename)
            print(&#34;Data saved in {}&#34;.format(filename))
        elif method is &#39;pickle&#39;:
            filename =  os.path.join(outputs_path, name) + &#39;.pkl&#39;
            pickle.dump(data, filename)
            print(&#34;Data saved in {}&#34;.format(filename))
        elif method is &#39;csv&#39;:
            data.to_csv(os.path.join(outputs_path, name) + &#39;.csv&#39;, index=False)
            print(&#34;Data saved successfully&#34;)
        else:
            logging.error(&#34;An error occured while savng the file&#34;)                    


    except FileNotFoundError as e:
        msg = &#34;outputs folder does not exist. Saving data to the current folder. It is recommended that you start your project using datasist&#39;s start_project function&#34;
        logging.info(msg)

        if method is &#34;joblib&#34;:
            filename =  name + &#39;.jbl&#39;
            joblib.dump(data, filename)
            print(&#34;Data saved in {}&#34;.format(filename))
        elif method is &#39;pickle&#39;:
            filename =  name + &#39;.pkl&#39;
            pickle.dump(data, filename)
            print(&#34;Data saved in {}&#34;.format(filename))
        elif method is &#39;csv&#39;:
            data.to_csv(name + &#39;.csv&#39;, index=False)
            print(&#34;Data saved successfully&#34;)
        else:
            logging.error(&#34;An error occured while savng the file&#34;)                              



def _get_home_path(filepath):
    if filepath.endswith(&#39;src&#39;):
        indx = filepath.index(&#34;src&#34;)
        path = filepath[0:indx]
        return path
    elif filepath.endswith(&#39;src/scripts/ingest&#39;):
        indx = filepath.index(&#34;src/scripts/ingest&#34;)
        path = filepath[0:indx]
        return path
    elif filepath.endswith(&#39;src/scripts/preparation&#39;):
        indx = filepath.index(&#34;src/scripts/preparation&#34;)
        path = filepath[0:indx]
        return path
    elif filepath.endswith(&#34;src/scripts/modeling&#34;):
        indx = filepath.index(&#34;src/scripts/modeling&#34;)
        path = filepath[0:indx]
        return path    
    elif filepath.endswith(&#34;src/notebooks&#34;):
        indx = filepath.index(&#34;src/notebooks&#34;)
        path = filepath[0:indx]
        return path
    else:
        return filepath


# if __name__ == &#34;__main__&#34;:
#     parser = argparse.ArgumentParser()
#     parser.add_argument(&#34;-p&#34;, &#34;--project_name&#34;, help=&#34;Name of the parent directory to initialize folders&#34;)
#     args = parser.parse_args()

#     start_project(args.project_name)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="datasist.project.save_data"><code class="name flex">
<span>def <span class="ident">save_data</span></span>(<span>data, name='processed_data', method='joblib', loc='processed')</span>
</code></dt>
<dd>
<section class="desc"><p>Saves data in the data folder. The data folder contains the processed and raw subfolders.</p>
<p>The processed subfolder holds data that have been processed by some methods and can be used for later computation. Files like
feature matrixes, clean data files etc.</p>
<p>The raw subfolder contains data in the raw format. This can be in the form of sql tables, csv files raw texts etc.
Folders must be initialized using the datasist start_project function.</p>
<h2 id="parameters">Parameters:</h2>
<p>data: binary strings, CSV, txt
Data to save in the specified folder</p>
<p>name: string, Default proc_data
Name of the data file to save.</p>
<p>method: string, Default None
Format to use in saving the data. It can be empty string, and we assume it is a
Pandas DataFrame, and we use the to_csv function, else we serialize with joblib.</p>
<p>loc: string, Default processed.
subfolder to save the data file to. Can be one of [processed, raw ]</p>
<h2 id="returns">Returns:</h2>
<p>None</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_data(data, name=&#39;processed_data&#39;, method=&#39;joblib&#39;, loc=&#39;processed&#39;):
    
    &#39;&#39;&#39;
    Saves data in the data folder. The data folder contains the processed and raw subfolders.

    The processed subfolder holds data that have been processed by some methods and can be used for later computation. Files like
    feature matrixes, clean data files etc.

    The raw subfolder contains data in the raw format. This can be in the form of sql tables, csv files raw texts etc.
    Folders must be initialized using the datasist start_project function.

    Parameters:
    ------------
    data: binary strings, CSV, txt
        Data to save in the specified folder

    name: string, Default proc_data
        Name of the data file to save.

    method: string, Default None
        Format to use in saving the data. It can be empty string, and we assume it is a 
        Pandas DataFrame, and we use the to_csv function, else we serialize with joblib.
    
    loc: string, Default processed.
        subfolder to save the data file to. Can be one of [processed, raw ]

    Returns:
    ---------
    None

    &#39;&#39;&#39;
    if data is None:
        raise ValueError(&#34;data: Expecting a dataset, got &#39;None&#39;&#34;)

    if loc not in [&#39;processed&#39;, &#39;raw&#39;]:
        raise ValueError(&#34;loc: location not found, expecting one of [processed , raw] got {}&#34;.format(loc))
    
    try:
        homepath = _get_home_path(os.getcwd())
        config_path = os.path.join(homepath, &#39;config.txt&#39;)
        
        with open(config_path) as configfile:
            config = json.load(configfile)
        
        data_path = os.path.join(config[&#39;datapath&#39;], loc)


        if method is &#34;joblib&#34;:
            filename =  os.path.join(data_path, name) + &#39;.jbl&#39;
            joblib.dump(data, filename)
            print(&#34;Data saved in {}&#34;.format(filename))

        else:
            try:
                data.to_csv(os.path.join(data_path, name) + &#39;.csv&#39;, index=False)
                print(&#34;Data saved successfully&#34;)

            except AttributeError as e:
                print(&#34;The file to save must be a Pandas DataFrame. Otherwise, change method parameter to joblib &#34;)
                logging.error(e)                     


    except FileNotFoundError as e:
        msg = &#34;data folder does not exist. Saving data to the {} folder. It is recommended that you start your project using datasist&#39;s start_project function&#34;.format(name)
        logging.info(msg)

        if method is &#34;joblib&#34;:
            filename = name + &#39;.jbl&#39;
            joblib.dump(data, filename)
            print(&#34;data saved in current working directory&#34;)
        else:
            try:
                data.to_csv(name + &#39;.csv&#39;,  index=False)
            except AttributeError as e:
                logging.info(&#34;The file to save must be a Pandas DataFrame, else change method to joblib &#34;)
                logging.error(e)                 </code></pre>
</details>
</dd>
<dt id="datasist.project.save_model"><code class="name flex">
<span>def <span class="ident">save_model</span></span>(<span>model, name='model', method='joblib')</span>
</code></dt>
<dd>
<section class="desc"><p>Save a trained machine learning model in the models folder.
Folders must be initialized using the datasist start_project function.
Creates a folder models if datasist standard directory is not provided.</p>
<h2 id="parameters">Parameters:</h2>
<p>model: binary file, Python object
Trained model file to save in the models folder.</p>
<p>name: string
Name of the model to save it with.</p>
<p>method: string
Format to use in saving the model. It can be one of [joblib, pickle or keras].</p>
<h2 id="returns">Returns:</h2>
<p>None</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_model(model, name=&#39;model&#39;, method=&#39;joblib&#39;):
    &#39;&#39;&#39;
    Save a trained machine learning model in the models folder.
    Folders must be initialized using the datasist start_project function.
    Creates a folder models if datasist standard directory is not provided.

    Parameters:
    ------------
    model: binary file, Python object
        Trained model file to save in the models folder.

    name: string
        Name of the model to save it with.

    method: string
        Format to use in saving the model. It can be one of [joblib, pickle or keras].

    Returns:
    ---------
    None

    &#39;&#39;&#39;

    if model is None:
        raise ValueError(&#34;model: Expecting a binary model file, got &#39;None&#39;&#34;)
   
    #get file path from config file
    #we assume that the user is saving the model from the models folder
    config = None

    try:
        homepath = _get_home_path(os.getcwd())
        config_path = os.path.join(homepath, &#39;config.txt&#39;)
        
        with open(config_path) as configfile:
            config = json.load(configfile)
        
        model_path = os.path.join(config[&#39;modelpath&#39;], name)

        if method is &#34;joblib&#34;:
            filename = model_path + &#39;.jbl&#39;
            joblib.dump(model, model_path)
            print(&#34;model saved in {}&#34;.format(filename))
        elif method is &#39;pickle&#39;:
            filename = model_path + &#39;.pkl&#39;
            pickle.dump(model, model_path)
            print(&#34;model saved in {}&#34;.format(filename))

        elif method is &#39;keras&#39;:
            filename = model_path + &#39;.h5&#39;
            model.save(filename)
            print(&#34;model saved in {}&#34;.format(filename))

        else:
            logging.error(&#34;{} not supported, specify one of [joblib, pickle, keras]&#34;.format(method))
            
    except FileNotFoundError as e:
        msg = &#34;models folder does not exist. Saving model to the {} folder. It is recommended that you start your project using datasist&#39;s start_project function&#34;.format(name)
        logging.info(msg)

        if method is &#34;joblib&#34;:
            filename = name + &#39;.jbl&#39;
            joblib.dump(model, filename)
            print(&#34;model saved in current working directory&#34;)
        elif method is &#39;pickle&#39;:
            filename = name + &#39;.pkl&#39;
            pickle.dump(model, filename)
            print(&#34;model saved in current working directory&#34;)

        elif method is &#39;keras&#39;:
            filename = name + &#39;.h5&#39;
            model.save(filename)
            print(&#34;model saved in current working directory&#34;)

        else:
            logging.error(&#34;{} not supported, specify one of [joblib, pickle, keras]&#34;.format(method))</code></pre>
</details>
</dd>
<dt id="datasist.project.save_outputs"><code class="name flex">
<span>def <span class="ident">save_outputs</span></span>(<span>data=None, name='proc_outputs', method='joblib')</span>
</code></dt>
<dd>
<section class="desc"><p>Saves files like vocabulary, class labels, mappings, encodings, images etc. in the outputs folder. </p>
<h2 id="parameters">Parameters:</h2>
<p>data: binary strings, CSV, txt
Data to save in the folder</p>
<p>name: string, Default proc_outputs
Name of the data file to save.</p>
<p>method: string, Default joblib
Format to use in saving the data. It can be one of [csv, joblib, pickle].</p>
<h2 id="returns">Returns:</h2>
<p>None</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_outputs(data=None, name=&#39;proc_outputs&#39;, method=&#39;joblib&#39;):

    &#39;&#39;&#39;
    Saves files like vocabulary, class labels, mappings, encodings, images etc. in the outputs folder. 
    
    Parameters:
    ------------
    data: binary strings, CSV, txt
        Data to save in the folder

    name: string, Default proc_outputs
        Name of the data file to save.

    method: string, Default joblib
        Format to use in saving the data. It can be one of [csv, joblib, pickle].

    Returns:
    ---------
    None

    &#39;&#39;&#39;
    if data is None:
        raise ValueError(&#34;data: Expecting a dataset, got &#39;None&#39;&#34;)

    if method not in [&#39;csv&#39;, &#39;joblib&#39;, &#39;pickle&#39;]:
        raise ValueError(&#34;method: Expecting one of [&#39;csv&#39;, &#39;joblib&#39;, &#39;pickle&#39;] got {}&#34;.format(method))
    
    try:
        homepath = _get_home_path(os.getcwd())
        config_path = os.path.join(homepath, &#39;config.txt&#39;)
        
        with open(config_path) as configfile:
            config = json.load(configfile)
        
        outputs_path = config[&#39;outputpath&#39;]


        if method is &#34;joblib&#34;:
            filename =  os.path.join(outputs_path, name) + &#39;.jbl&#39;
            joblib.dump(data, filename)
            print(&#34;Data saved in {}&#34;.format(filename))
        elif method is &#39;pickle&#39;:
            filename =  os.path.join(outputs_path, name) + &#39;.pkl&#39;
            pickle.dump(data, filename)
            print(&#34;Data saved in {}&#34;.format(filename))
        elif method is &#39;csv&#39;:
            data.to_csv(os.path.join(outputs_path, name) + &#39;.csv&#39;, index=False)
            print(&#34;Data saved successfully&#34;)
        else:
            logging.error(&#34;An error occured while savng the file&#34;)                    


    except FileNotFoundError as e:
        msg = &#34;outputs folder does not exist. Saving data to the current folder. It is recommended that you start your project using datasist&#39;s start_project function&#34;
        logging.info(msg)

        if method is &#34;joblib&#34;:
            filename =  name + &#39;.jbl&#39;
            joblib.dump(data, filename)
            print(&#34;Data saved in {}&#34;.format(filename))
        elif method is &#39;pickle&#39;:
            filename =  name + &#39;.pkl&#39;
            pickle.dump(data, filename)
            print(&#34;Data saved in {}&#34;.format(filename))
        elif method is &#39;csv&#39;:
            data.to_csv(name + &#39;.csv&#39;, index=False)
            print(&#34;Data saved successfully&#34;)
        else:
            logging.error(&#34;An error occured while savng the file&#34;)                              </code></pre>
</details>
</dd>
<dt id="datasist.project.start_project"><code class="name flex">
<span>def <span class="ident">start_project</span></span>(<span>project_name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Creates a standard data science project directory. This helps in
easy team collaboration, rapid prototyping, easy reproducibility and fast iteration. </p>
<p>The directory structure is by no means a globally recognized standard, but was inspired by
the folder structure created by the Azure team (<a href="https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview">https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview</a>)
and Edward Ma (<a href="https://makcedward.github.io/">https://makcedward.github.io/</a>) of OOCL.</p>
<h3 id="project-structure">PROJECT STRUCTURE:</h3>
<pre><code>    ├── data
    │   ├── processed
    │   └── raw
    ├── outputs
    │   ├── models
    ├── src
    │   ├── scripts
    │       ├── ingest
    │       ├── modeling
    │       ├── preparation
    │       ├── test
    ├   ├── notebooks



    DETAILS:

    data: Stores data used for the experiments, including raw and intermediate processed data.
        processed: stores all processed data files after cleaning, analysis, feature creation etc.
        raw: Stores all raw data obtained from databases, file storages, etc.

    outputs:Stores all output files from an experiment.
        models: Stores trained binary model files. This are models saved after training and evaluation for later use.

    src: Stores all source code including scripts and notebook experiments.
        scripts: Stores all code scripts usually in Python/R format. This is usually refactored from the notebooks.
            modeling: Stores all scripts and code relating to model building, evaluation and saving.
            preparation: Stores all scripts used for data preparation and cleaning.
            ingest: Stores all scripts used for reading in data from different sources like databases, web or file storage.
            test: Stores all test files for code in scripts.
        notebooks: Stores all jupyter notebooks used for experimentation.
</code></pre>
<h2 id="parameters">Parameters:</h2>
<p>project_name: String, Filepath
Name of filepath of the directory to initialize and create folders.</p>
<h2 id="returns">Returns:</h2>
<p>None</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def start_project(project_name=None):
    &#39;&#39;&#39;
    Creates a standard data science project directory. This helps in
    easy team collaboration, rapid prototyping, easy reproducibility and fast iteration. 
    
    The directory structure is by no means a globally recognized standard, but was inspired by
    the folder structure created by the Azure team (https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview)
    and Edward Ma (https://makcedward.github.io/) of OOCL.
    
    ### PROJECT STRUCTURE:

            ├── data
            │   ├── processed
            │   └── raw
            ├── outputs
            │   ├── models
            ├── src
            │   ├── scripts
            │       ├── ingest
            │       ├── modeling
            │       ├── preparation
            │       ├── test
            ├   ├── notebooks



            DETAILS:

            data: Stores data used for the experiments, including raw and intermediate processed data.
                processed: stores all processed data files after cleaning, analysis, feature creation etc.
                raw: Stores all raw data obtained from databases, file storages, etc.

            outputs:Stores all output files from an experiment.
                models: Stores trained binary model files. This are models saved after training and evaluation for later use.

            src: Stores all source code including scripts and notebook experiments.
                scripts: Stores all code scripts usually in Python/R format. This is usually refactored from the notebooks.
                    modeling: Stores all scripts and code relating to model building, evaluation and saving.
                    preparation: Stores all scripts used for data preparation and cleaning.
                    ingest: Stores all scripts used for reading in data from different sources like databases, web or file storage.
                    test: Stores all test files for code in scripts.
                notebooks: Stores all jupyter notebooks used for experimentation.
    
    
    Parameters:
    -------------
    project_name: String, Filepath
            Name of filepath of the directory to initialize and create folders.
    
    Returns:
    -------------
    None
    
    &#39;&#39;&#39;
    if project_name is None:
        raise ValueError(&#34;project_name: Expecting a string or filepath, got &#39;None&#39;&#34;)

    
    base_path = os.path.join(os.getcwd(), project_name)
    data_path = os.path.join(base_path, &#39;data&#39;)
    output_path = os.path.join(base_path, &#39;outputs&#39;)
    model_path = os.path.join(output_path, &#39;models&#39;)
    src_path = os.path.join(base_path, &#39;src&#39;)
    scripts_path = os.path.join(base_path, &#39;src&#39;, &#39;scripts&#39;)

    
    os.makedirs(data_path, exist_ok=True)
    os.makedirs(os.path.join(data_path, &#39;raw&#39;), exist_ok=True)
    os.makedirs(os.path.join(data_path, &#39;processed&#39;), exist_ok=True)

    os.makedirs(os.path.join(output_path), exist_ok=True)
    os.makedirs(os.path.join(model_path), exist_ok=True)

    os.makedirs(os.path.join(src_path), exist_ok=True)
    os.makedirs(os.path.join(src_path, &#39;notebooks&#39;), exist_ok=True)

    os.makedirs(os.path.join(scripts_path), exist_ok=True)
    os.makedirs(os.path.join(scripts_path, &#39;ingest&#39;), exist_ok=True)
    os.makedirs(os.path.join(scripts_path, &#39;preparation&#39;), exist_ok=True)
    os.makedirs(os.path.join(scripts_path, &#39;modeling&#39;), exist_ok=True)
    os.makedirs(os.path.join(scripts_path, &#39;test&#39;), exist_ok=True)


    
    desc = &#39;&#39;&#39;
    PROJECT STRUCTURE:

            ├── data
            │   ├── processed
            │   └── raw
            ├── outputs
            │   ├── models
            ├── src
            │   ├── scripts
            │       ├── ingest
            │       ├── modeling
            │       ├── preparation
            │       ├── test
            ├   ├── notebooks


            data: Stores data used for the experiments, including raw and intermediate processed data.
                processed: stores all processed data files after cleaning, analysis, feature creation etc.
                raw: Stores all raw data obtained from databases, file storages, etc.

            outputs:Stores all output files from an experiment.
                models: Stores trained binary model files. This are models saved after training and evaluation for later use.

            src: Stores all source code including scripts and notebook experiments.
                scripts: Stores all code scripts usually in Python/R format. This is usually refactored from the notebooks.
                    modeling: Stores all scripts and code relating to model building, evaluation and saving.
                    preparation: Stores all scripts used for data preparation and cleaning.
                    ingest: Stores all scripts used for reading in data from different sources like databases, web or file storage.
                    test: Stores all test files for code in scripts.
                notebooks: Stores all jupyter notebooks used for experimentation.

    &#39;&#39;&#39; 
    #project configuration settings
    json_config = {&#34;description&#34;: &#34;This file holds all confguration settings for the current project&#34;,
                    &#34;basepath&#34;: base_path,
                    &#34;datapath&#34; : data_path,
                    &#34;outputpath&#34;: output_path,
                    &#34;modelpath&#34;: model_path}
    
    #create a readme.txt file to explain the folder structure
    with open(os.path.join(base_path, &#34;README.txt&#34;), &#39;w&#39;) as readme:
        readme.write(desc)
    
    with open(os.path.join(base_path, &#34;config.txt&#34;), &#39;w&#39;) as configfile:
        json.dump(json_config, configfile)
    
    print(&#34;Project Initialized successfully in {}&#34;.format(base_path))
    print(&#34;Check folder description in ReadMe.txt&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="datasist" href="index.html">datasist</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="datasist.project.save_data" href="#datasist.project.save_data">save_data</a></code></li>
<li><code><a title="datasist.project.save_model" href="#datasist.project.save_model">save_model</a></code></li>
<li><code><a title="datasist.project.save_outputs" href="#datasist.project.save_outputs">save_outputs</a></code></li>
<li><code><a title="datasist.project.start_project" href="#datasist.project.start_project">start_project</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.2</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>